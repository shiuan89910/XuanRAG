# 0. 目錄
- [1. 大型語言模型 (LLM) 參數 Offload 的檔案路徑](#1-大型語言模型-llm-參數-offload-的檔案路徑)
  - [1.1. 概述](#11-概述)
  - [1.2. 參數 Offload 的必要性](#12-參數-offload-的必要性)
  - [1.3. 注意事項](#13-注意事項)


# 1. 大型語言模型 (LLM) 參數 Offload 的檔案路徑


## 1.1. 概述
大型語言模型 (LLM) 擁有龐大的參數量對計算資源要求非常高。這些模型在訓練或推理時需要大量的 GPU 記憶體（RAM）。
然而當可用的 GPU RAM 不足以裝載整個模型的所有參數時，可以採用參數 Offload 技術將部分模型參數卸載至 CPU 的 RAM 上。


## 1.2. 參數 Offload 的必要性
- **資源限制**：在硬件資源受限的情況下，特別是 GPU RAM 容量不足時，參數 Offload 可以使大型模型得以執行。
- **成本效益**：透過利用 CPU RAM，可以在不額外增加昂貴 GPU 資源的情況下，運行大型模型。


## 1.3. 注意事項
- **性能影響**：雖然參數 Offload 可以解決記憶體容量的問題，但由於 CPU 與 GPU 之間的數據交換速度較慢，可能會影響模型的執行效率。
